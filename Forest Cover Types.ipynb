{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rborra/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Let's first import required Python packages.\n",
    "#Importing required Python packages\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pandas as pd\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traincsv=pd.read_csv('train.csv', index_col='Id')\n",
    "testcsv=pd.read_csv('test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12096, 54) (3024, 54) (12096,) (3024,)\n"
     ]
    }
   ],
   "source": [
    "#80/20 Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(traincsv.iloc[:,:-1].values, traincsv.iloc[:,-1:].values.ravel(), \n",
    "                                                    test_size=0.2)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=14,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC=RandomForestClassifier(max_depth=14, n_estimators=1000)\n",
    "RFC.fit(X_train, y_train)\n",
    "\n",
    "ETC= ExtraTreesClassifier(max_depth=14, n_estimators=1000)\n",
    "ETC.fit(X_train, y_train)\n",
    "\n",
    "GBC= GradientBoostingClassifier(max_depth=14, n_estimators=1000)\n",
    "GBC.fit(X_train, y_train)\n",
    "\n",
    "XGB= XGBClassifier(max_depth=14, n_estimators=1000)\n",
    "XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "1 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=1000, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "2 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=14,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1000, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "3 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=14,\n",
      "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "estimators = [RFC, ETC, GBC,XGB]\n",
    "\n",
    "X_blend_train=[]\n",
    "X_blend_test=[]\n",
    "X_blend_testcsv=[]\n",
    "\n",
    "for i, est in enumerate(estimators):\n",
    "    print i , est\n",
    "    X_blend_train.append(est.predict(X_train))\n",
    "    X_blend_test.append(est.predict(X_test))\n",
    "    X_blend_testcsv.append(est.predict(testcsv.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blend_train = np.array(X_blend_train).T\n",
    "X_blend_test = np.array(X_blend_test).T\n",
    "X_blend_testcsv = np.array(X_blend_testcsv).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "#lo=LogisticRegression().fit(X_blend_train, y_train) \n",
    "#y_pred=lo.predict(X_blend_test)\n",
    "\n",
    "XGB2= XGBClassifier(max_depth=14, n_estimators=1000).fit(X_blend_train, y_train) \n",
    "y_pred=XGB2.predict(X_blend_test)\n",
    "\n",
    "#Make a copy of the test.csv \n",
    "temp=testcsv.copy()\n",
    "\n",
    "#Run Predictions on test.csv \n",
    "temp['Cover_Type']=XGB2.predict(X_blend_testcsv) \n",
    "\n",
    "#Create Submissions csv file \n",
    "temp=temp['Cover_Type'] \n",
    "temp.to_csv('SampleSubmission11', header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Public Score : 0.74605"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
